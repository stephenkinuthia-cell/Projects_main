
# Fraud Detection System Template (Enhanced)
# Author: ChatGPT
# Date: 2025-06-02

# ðŸ“¦ Step 1: Import Required Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import zscore, poisson, beta
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay

# ðŸ§¹ Step 2: Load or Create Synthetic Data
np.random.seed(42)

# Simulate normal transaction behavior
n_normal = 1000
amounts = np.random.normal(loc=50, scale=10, size=n_normal)
times = np.random.exponential(scale=30, size=n_normal)

# Add fraud cases
n_fraud = 20
fraud_amounts = np.random.normal(loc=200, scale=30, size=n_fraud)
fraud_times = np.random.exponential(scale=5, size=n_fraud)

# Combine data
amounts_all = np.concatenate([amounts, fraud_amounts])
times_all = np.concatenate([times, fraud_times])
labels = np.array([0]*n_normal + [1]*n_fraud)  # 0 = normal, 1 = fraud

df = pd.DataFrame({
    'amount': amounts_all,
    'time_since_last': times_all,
    'is_fraud': labels
})

# ðŸ“ˆ Step 3: Anomaly Detection

# Z-score method
df['z_amount'] = zscore(df['amount'])
df['z_time'] = zscore(df['time_since_last'])
df['z_outlier'] = ((df['z_amount'].abs() > 3) | (df['z_time'].abs() > 3)).astype(int)

# Poisson method
lambda_poisson = df[df['is_fraud'] == 0]['time_since_last'].mean()
df['poisson_prob'] = poisson.pmf(np.round(df['time_since_last']), mu=lambda_poisson)
df['poisson_anomaly'] = (df['poisson_prob'] < 0.01).astype(int)

# Mahalanobis distance
from scipy.spatial import distance

def mahalanobis_dist(row, mean, cov_inv):
    x = np.array([row['amount'], row['time_since_last']])
    return distance.mahalanobis(x, mean, cov_inv)

X = df[['amount', 'time_since_last']]
mean_vec = X.mean().values
cov_mat = np.cov(X.T)
cov_inv = np.linalg.inv(cov_mat)
df['mahalanobis'] = X.apply(mahalanobis_dist, axis=1, args=(mean_vec, cov_inv))
df['mahalanobis_outlier'] = (df['mahalanobis'] > 3.0).astype(int)

# Isolation Forest
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
iso = IsolationForest(contamination=0.02, random_state=42)
df['isolation_outlier'] = (iso.fit_predict(X_scaled) == -1).astype(int)

# ðŸ§® Step 4: Evaluation Metrics
methods = ['z_outlier', 'poisson_anomaly', 'mahalanobis_outlier', 'isolation_outlier']

for method in methods:
    print(f"\n--- {method.upper()} ---")
    cm = confusion_matrix(df['is_fraud'], df[method])
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Fraud'])
    disp.plot()
    plt.title(f"Confusion Matrix: {method}")
    plt.show()
    precision = precision_score(df['is_fraud'], df[method])
    recall = recall_score(df['is_fraud'], df[method])
    print(f"Precision: {precision:.2f}, Recall: {recall:.2f}")

# ðŸ“Š Step 5: Bayesian Updating of Fraud Probability
# Use Beta distribution as prior for fraud rate (e.g., assume prior 2 frauds in 100 transactions)

alpha_prior = 2
beta_prior = 98

fraud_detected = df['isolation_outlier'].sum()
non_fraud_detected = len(df) - fraud_detected

alpha_post = alpha_prior + fraud_detected
beta_post = beta_prior + non_fraud_detected

x = np.linspace(0, 0.1, 1000)
posterior = beta.pdf(x, alpha_post, beta_post)

plt.plot(x, posterior)
plt.title("Posterior Fraud Rate Distribution (Bayesian Update)")
plt.xlabel("Fraud Probability")
plt.ylabel("Density")
plt.grid(True)
plt.show()

# ðŸ“² Step 6: Streamlit Dashboard Hint (Run in a .py with `streamlit run app.py`)
'''
# fraud_dashboard.py
import streamlit as st

st.title("Fraud Detection Dashboard")

st.write("## Sample Transactions")
st.dataframe(df[['amount', 'time_since_last', 'z_outlier', 'isolation_outlier', 'is_fraud']].head(20))

st.write("## Fraud Probability Estimate (Bayesian)")
st.line_chart(posterior)
'''
